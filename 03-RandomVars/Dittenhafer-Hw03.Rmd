---
title: "Homework 3"
subtitle: "DATA604 Simulation and Modeling"
author: "Daniel Dittenhafer"
date: "March 6, 2016"
output: pdf_document
classoption: portrait
geometry: margin=0.5in
---
```{r, echo=FALSE, message=FALSE}
library(knitr)
library(gplots)
library(ggplot2)
library(gridExtra)
library(plot3D)
library(tseries)
set.seed(20275)
# My ggplot theme
myTheme <- theme(axis.ticks=element_blank(),
                 axis.title=element_text(size="10"),
                  panel.border = element_rect(color="gray", fill=NA), 
                  panel.background=element_rect(fill="#FBFBFB"), 
                  panel.grid.major.y=element_line(color="white", size=0.5), 
                  panel.grid.major.x=element_line(color="white", size=0.5),
                  plot.title=element_text(size="10"))
```

```{r, echo=FALSE, message=FALSE}
library(knitcitations)
library(RefManageR)

cleanbib()

cite_options(style="markdown")

bibPkgTseries <- bibentry(bibtype="Misc",
                 author=personList(person(family="Trapletti", given="Adrian"), 
                                   person(family="Hornik", given="Kurt")),
                 journal="Annual Review of Sociology",
                 title="tseries: Time Series Analysis and Computational Finance",
                 year=2015,
                 note="R package version 0.10-34",
                 url="http://CRAN.R-project.org/package=tseries")
```

## 1

*Starting with \(X_0=1\), write down the entire cycle for \(X_i=11X_{i-1}\text{ mod}(16)\)*

```{r}
fn1 <- function(x0)
{
  df <- data.frame(X=c(), R=c())  
  x <- x0
  continue <- TRUE
  
  while(continue)
  {
    xi <- (11 * x) %% 16
    df <- rbind(df, data.frame(X=x, R=xi))
    x <- xi
    
    if(xi == x0)
    {
      break
    }
  }
  
  return(df)
}

res <- fn1(1)
```

```{r, echo=FALSE}
kable(res)
```


## 2

*Using the LCG provided below: \(X_i=(X_{i-1} + 12) mod(13)\), plot the pairs \((U_1.U_2), (U_2, U_3),...\) and observe the lattice structure obtained. Discuss what you observe.*

```{r}
fn2 <- function(x0, max=100)
{
  df <- data.frame(U1=c(), U2=c())  
  x <- x0
  
  for(i in 1:max)
  {
    xi <- (x + 12) %% 13
    df <- rbind(df, data.frame(U1=x, U2=xi))
    x <- xi
  }
  
  return(df)  
}
# Call the function starting at x0=1
res <- fn2(25)
```


```{r, echo=FALSE, fig.height=3, fig.width=3}
g21 <- ggplot(res) + geom_point(aes(x=U1, y=U2), alpha=0.25) + myTheme
g21
```

The chart above suggests there are only 13 points, but actually the LCG cycle period is 13 and numbers are repeating.

```{r, echo=FALSE}
kable(head(res, 14))
```

## 3

*Implement the pseudo-random number generator:*

\[X_i = 16807X_{i-1} \text{ mod}(2^{31} - 1)\]

*Using the seed 1234567, run the generator for 100,000 observations. Perform a chi-square goodness-of-fit test on the resulting PRN's. Use 20 equal-probability intervals and level \(\alpha = 0.05\). Now perform a runs up-and-down test with \(\alpha = 0.05\) on the observvations to see if they are independent.*

```{r}
fnLCG3 <- function(seed = 1, n = 1)
{
  rands <- rep(NA, n) 
  x <- seed
  modVal <- (2^31 - 1)
  
  for(i in 1:n)
  {
    xi <- (16807 * x) %% (modVal)
    rands[i] <- xi
    x <- xi
  }
  
  return(rands)  
}

n=100000
rn <- fnLCG3(1234567, n)
```

The first 6 generated numbers are shown below:

```{r, echo=FALSE}
kable(head(rn))
```

```{r, echo=FALSE, fig.height=3, message=FALSE}
#g3 <- ggplot(data.frame(random=rn)) + geom_histogram(aes(x=random), bins=20) + myTheme
#g3
```

### Chi-Square Test

```{r}
intervals <- 20
maxRn <- max(rn)
minRn <- min(rn)
intWidth <- (maxRn - minRn) / intervals
lwr <- minRn
dfCounts <- data.frame(intID=c(), count=c())
# Bin the data ourselves, I'd guess there 
# is an easier way, but this will do.
for(i in 1:intervals)
{
  upr <- lwr + intWidth
  inRange <- rn[lwr <= rn & rn < upr]
  dfCounts <- rbind(dfCounts, data.frame(intID=i, count=length(inRange)))
  # setup for next interval range
  lwr <- upr
}
# Do our own Chi-Squared test
Expected <- (100000 / intervals)
chi2 <- sum((dfCounts$count - Expected)^2 / Expected)
chi2
# Use built-in function to compare
chiTest <- chisq.test(dfCounts$count)
chiTest
```

The p-value = `r chiTest$p.value` is not less than \(\alpha = 0.05\), therefore we don't reject the null hypothesis that the distrubtion is uniform. 

```{r, echo=FALSE}
kable(dfCounts)
```

### Runs Up-and-Down Test

Using the `tseries` package, we execute the Runs test `r citep(bibPkgTseries)`. First we have to construct the +/- vector. Here we simply convert to boolean.

```{r}
s <- rep(NA, n - 1)
for(i in 1:n - 1)
{
  s[i] <- rn[i] < rn[i + 1]
}

runsTest <- runs.test(as.factor(s))
runsTest
```

Based on the p-value < 0.05, we reject the null hypothesis and conclude there is not evidence to support independence in the psuedo-random numbers.


## 4. 

*Give inverse-transforms, composition, and acceptance-rejection algorithms for generating from the following density:*

\[f(x)=
  \begin{cases} 
    \frac{3x^2}{2} & -1 \leq x \leq 1 \\
    0              & otherwise  \\
  \end{cases}
\]

### Inverse-Transforms

First find the indefinite integral of the probability density function:

\[F(x)=\int\frac{3x^2}{2} dx = \frac{x^3}{2}\]

Next set \(F(x)=R\) and solve for x in terms of R:

\[\frac{x^3}{2} = R\]

\[x^3 = 2R\]

\[F^-1(x) = \sqrt[3]{2R}\]

```{r}
# Define a function of the F^-1(X)
invTfn4 <- function(r)
{
  vals <- (2 * r)^(1/3)
  return (vals)
}

# Generate the uniform psuedo-random vars
rVals <- runif(n, -1, 1)
# Convert to the desired distribution using the inverse transform method.
invTVals <- invTfn4(rVals)
```

```{r, echo=FALSE, fig.height=3, message=FALSE}
g41 <- ggplot(data.frame(invT=invTVals)) + geom_histogram(aes(x=invT)) + 
  myTheme +
  xlim(-1, 1) +
  labs(title="Empircial Distribution from Inverse Transform Method")

g41
```

### Acceptance-Rejection Method

```{r}
# Helper function for the Accept/Reject approach
myRARmethod <- function(fun, min, max)
{
  M <- 2
  accepted <- FALSE
  while(!accepted)
  {
    # Get a random value from uniform distrubtion (g(x) for us)
    r <- runif(1, min, max)

    # Sample x from g(x) and u from U(0,1) (the uniform distribution over the unit interval)
    u <- runif(1, 0, 1)
    gx <- dunif(r, min, max)

    # Check whether or not u<f(x)/Mg(x). 
    if(u < fun(r) / (M * gx))
    {
      accepted = TRUE
    }
  }

  return(r)
}

# Define a function for the PDF
Arfn4 <- function(x)
{
  if(-1 <=x && x <= 1)
  {
    val <- (3 * x^2) / 2
  }
  else
  {
    val = 0
  }
  return (val)
}

# Loop to generate the values
rarVals <- rep(NA, n)
for(i in 1:n)
{
  rarVals[i] <- myRARmethod(Arfn4, -1, 1)  
}

```

```{r, echo=FALSE, fig.height=3}

g42 <- ggplot(data.frame(ar=rarVals)) + geom_histogram(aes(x=ar)) + myTheme +
  labs(title="Accept-Reject Methods")
g42
```

### Composition 

Hmm....


## 5

*Implement, test and compare different methods to generate from a N(0,1) distribution.*

\[f(x)=\frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}} \]


### Inverse Transform Method

\[F(X)=\int \frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}}  dx\]

It turns out the `qnorm` function is the inverse normal CDF function, so we'll use it.

```{r, message=FALSE}
normrandit <- function()
{
  u <- runif(1)
  return (qnorm(u))
}

itstats <- function(n)
{
  vals <- rep(NA, n)
  for(i in 1:n)
  {
    vals[i] <- normrandit()
  }
  
  return(list(values=vals, mean=mean(vals), sd=sd(vals)))
}

res <- itstats(10000)
res$mean
res$sd
```


```{r, echo=FALSE, fig.height=3}
g51 <- ggplot(data.frame(r=res[[1]])) + geom_histogram(aes(x=r)) + 
  myTheme +
  labs(title="Inverse Transform Method")
g51
```

### Box-Muller Method

```{r}
normrandbm <- function()
{
  u2 <- runif(2)
  
  v1 <- (-2 * log(u2[1]))^(1/2) * cos(2 * pi * u2[2])
  v2 <- (-2 * log(u2[1]))^(1/2) * sin(2 * pi * u2[2])
  
  return (c(v1, v2))
}

bmstats <- function(n)
{
  vals <- rep(NA, n)
  for(i in seq(1, n, by=2))
  {
    rs <- normrandbm()
    vals[i] <- rs[1]
    vals[i + 1] <- rs[2]
  }
  
  return(list(values=vals, mean=mean(vals), sd=sd(vals)))
}

resBm <- bmstats(10000)
length(resBm[[1]])
# Mean
resBm$mean
# SD
resBm$sd
```


```{r, echo=FALSE, fig.height=3, message=FALSE}
g52 <- ggplot(data.frame(r=resBm[[1]])) + geom_histogram(aes(x=r)) + 
  myTheme +
  labs(title="Box-Muller Method")
g52
```

### Accept Reject Method

```{r}
normrandar <- function()
{
  continue <- TRUE
  while(continue)
  {
    u2 <- runif(2)
    eu2 <-  - log(u2)
    
    if(eu2[2] >= ( (eu2[1] - 1)^2 / 2) )
    {
      break
    }   
  }
  
  sign <- runif(1)
  if(sign > 0.5)
  {
    eu2[1] <- eu2[1] * -1    
  }
  
  return(eu2[1])
}

arstats <- function(n)
{
  vals <- rep(NA, n)
  for(i in seq(1, n))
  {
    rs <- normrandar()
    vals[i] <- rs
    #vals[i + 1] <- rs[2]
  }
  
  return(list(values=vals, mean=mean(vals), sd=sd(vals))) 
}
```

### Compare

```{r}
dfCompare <- data.frame(method=c(), N=c(), mean=c(), sd=c(), time=c())

perfTest <- function(fun)
{
  dfResult <- data.frame(method=c(), N=c(), mean=c(), sd=c(), time=c())
  Ns <- c(100, 1000, 10000, 100000)
  it <- 2
  
  for(n in Ns)
  {
    m <- rep(NA, it)
    s <- rep(NA, it)
    t <- rep(NA, it)
    for(i in 1:it)
    {
      st <- system.time({ret <-  fun(n)})
      #print(st)
      m[i] <- ret$mean
      s[i] <- ret$sd
      t[i] <- st[[3]]
    }
    
    dfResult <- rbind(dfResult, data.frame(method=deparse(substitute(fun)), 
                                           N=n, 
                                           mean=mean(m), 
                                           sd=mean(s),
                                           time=mean(t)))
  }
  
  return (dfResult)
}
# Force less use of scientific notation
# http://stackoverflow.com/questions/9397664/force-r-not-to-use-exponential-notation-e-g-e10
options("scipen"=100, "digits"=5)

dfCompare <- rbind(dfCompare, perfTest(itstats))
dfCompare <- rbind(dfCompare, perfTest(bmstats))
dfCompare <- rbind(dfCompare, perfTest(arstats))
```

```{r, echo=FALSE}
kable(dfCompare)
```

```{r, echo=FALSE, fig.height=3}
g55 <- ggplot(dfCompare) + geom_line(aes(x=N, y=mean, colour=method)) + 
  myTheme +
  labs(title="Means by Approach")
g55
```

```{r, echo=FALSE, fig.height=3}
g56 <- ggplot(dfCompare) + geom_line(aes(x=N, y=sd, colour=method)) + 
  myTheme +
  labs(title="Stdev by Approach")
g56
```

```{r, echo=FALSE, fig.height=3}
g57 <- ggplot(dfCompare) + geom_line(aes(x=N, y=time, colour=method)) + 
  myTheme +
  labs(title="Time by Approach")
g57
```

For me, the Box-Muller approach takes the least time with Inverse Transform close behind. Also, I found that
preallocating the vector in the stats method had a significant effect on performance. If the vector is not fully
allocated, the time for the 100K samples jumps to 30+ seconds.

### Million Sample Histograms

```{r}
filename <- "MillionSamples.RData"
if(!file.exists(filename))
{
  m <- 1000000
  itMil <- itstats(m)
  bmMil <- bmstats(m)
  arMil <- arstats(m)
  
  dfItStats <- data.frame(method=rep("itstats", m), r=itMil$values)
  dfBmStats <- data.frame(method=rep("bmstats", m), r=bmMil$values)
  dfArStats <- data.frame(method=rep("arstats", m), r=arMil$values)
  
  #dfAll$method <- as.factor(dfAll$method)
  
  #save(dfAll, file=filename)
} else
{
  load(filename)
}
```

```{r, echo=FALSE, message=FALSE, fig.height=3}
g58 <- ggplot(dfItStats) + geom_histogram(aes(x=r)) + myTheme  + labs(title="Inverse Transform Histogram")
g58
```

```{r, echo=FALSE, message=FALSE, fig.height=3}
g59 <- ggplot(dfBmStats) + geom_histogram(aes(x=r)) + myTheme + labs(title="Box Muller Histogram")
g59
```

```{r, echo=FALSE, message=FALSE, fig.height=3}
g591 <- ggplot(dfArStats) + geom_histogram(aes(x=r)) + myTheme + labs(title="Accept/Reject Histogram")
g591
```

## 6

***Use Monte Carlo integration to estimate the value of \(\pi\).***

```{r, eval=TRUE}

# Define a function of the circle
quarterCircleY <- function(x)
{
  val <- sqrt((-1 * x^2) + 1)
  return (val)
}

insidecircle <- function(x, y)
{
  yq <- quarterCircleY(x)
  inside <- y <= yq
  
  return (inside)
}

# Define function for the Monte Carlo iterations
estimatepi <- function(n, mc=1)
{
  #mc <- 100
  dfMcPi <- data.frame()
  for(i in 1:mc)
  {
    #dfMcPoints <- monteCarloPiEst(n_points)
    dfPoints <- data.frame()
    x <- runif(n)
    y <- runif(n)
    
    inside <- insidecircle(x, y)
  
    dfPoints <- data.frame(x, y, inside)
    
    #return (dfPoints)
    
    # Compute quarter circle area under the curve
    qca <- sum(dfPoints$inside) / nrow(dfPoints)
    qca
    # estimate Pi
    pi_est <- qca * 4
    
    # Add to our running list.
    dfMcPi <- rbind(dfMcPi, cbind(i, pi_est))
  }
  mnPi <- mean(dfMcPi$pi_est)
  se <- sd(dfMcPi$pi_est) / sqrt(n)
  ci95 <- c(mnPi - (se * 1.96), mnPi + (se * 1.96))
  
  return(list(pi_est=mnPi, se=se, ci95=ci95, mc_results=dfMcPi, points=dfPoints))
}


dfRes <- data.frame(pi_est=c(), se=c(), lwr=c(), upr=c(), n=c())
for(ni in seq(1000, 10000, by=500))
{
  resPi <- estimatepi(ni, mc=100)
  dfRes <- rbind(dfRes, data.frame(pi_est=resPi$pi_est, 
                                   se=resPi$se, 
                                   lwr=resPi$ci95[1], 
                                   upr=resPi$ci95[2], n=ni))
}

```

```{r}
kable(dfRes)
```

Using n=8500:

```{r}
n=8500
dfRes2 <- data.frame(pi_est=c(), se=c(), lwr=c(), upr=c(), n=c())
for(k in 1:500)
{
  resPi <-estimatepi(n, mc=100)
  dfRes2 <- rbind(dfRes2, data.frame(pi_est=resPi$pi_est, se=resPi$se, lwr=resPi$ci95[1], upr=resPi$ci95[2], n=n))
}
```

```{r, echo=FALSE, fig.height=3}
g1 <- ggplot(data=dfRes2) + geom_histogram(aes(x=pi_est)) + myTheme
g1
```

```{r}
theRow <- dfRes[dfRes$n == n,]

sdEstPi <- sd(dfRes2$pi_est)
sdEstPi
```

Standard deviation does not quite match the SE from earlier (`r theRow$se`).  

```{r}
subCI <- dfRes2$pi_est[theRow$lwr <= dfRes2$pi_est & dfRes2$pi_est <= theRow$upr]

prop95 <- length(subCI) / 500
prop95
```
## References


```{r, results='asis', echo=FALSE}
BibOptions(style="html", bib.style="authortitle")
bibliography()
```
  